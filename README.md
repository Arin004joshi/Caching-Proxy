# ğŸš€ Caching Proxy Server

> A high-performance CLI tool that creates a caching proxy server to accelerate API responses and reduce server load.

## âœ¨ Features

- ğŸ”„ **Universal Proxy** - Forwards any HTTP request to the origin server
- âš¡ **Smart Caching** - Caches GET responses for lightning-fast subsequent requests
- ğŸ•’ **TTL Support** - Automatic cache expiration (5 minutes default)
- ğŸ“Š **Cache Headers** - Adds `X-Cache: HIT/MISS` headers for debugging
- ğŸ›  **CLI Interface** - Easy command-line configuration
- ğŸ”§ **Error Handling** - Graceful handling of connection failures
- ğŸ“ˆ **Performance Boost** - Significantly reduces response times for repeated requests

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+ installed

### Installation

```bash
# Clone the repository
git clone https://github.com/Arin004joshi/Caching-Proxy.git
cd Caching-Proxy

# Install dependencies
npm install

# Make executable (optional)
chmod +x index.js
```

### Usage

```bash
# Basic usage
node index.js --origin http://dummyjson.com --port 3000

# Custom port
node index.js --origin https://jsonplaceholder.typicode.com --port 8080

# Ready to go - no additional setup required!
node index.js --origin http://api.example.com --port 3000
```

## ğŸ“– How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client  â”‚â”€â”€â”€â–¶â”‚ Caching Proxy   â”‚â”€â”€â”€â–¶â”‚ Origin Serverâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚                 â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
               â”‚ â”‚    Cache    â”‚ â”‚
               â”‚ â”‚  Storage    â”‚ â”‚
               â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Request arrives** at the proxy server
2. **Cache check** - if response exists and is fresh, return immediately âš¡
3. **Forward request** to origin server if cache miss
4. **Store response** in cache for future requests
5. **Return response** to client with cache status header

## ğŸ¯ Example Usage

### Test Cache Miss (First Request)
```bash
curl -I http://localhost:3000/products/1
# Returns: X-Cache: MISS
```

### Test Cache Hit (Subsequent Request)
```bash
curl -I http://localhost:3000/products/1
# Returns: X-Cache: HIT (much faster!)
```

### Different Endpoints
```bash
# All these work automatically
curl http://localhost:3000/users
curl http://localhost:3000/posts/1
curl http://localhost:3000/api/data
```

## âš™ï¸ Configuration Options

| Option | Description | Default | Required |
|--------|-------------|---------|----------|
| `--port` | Port to run the proxy server | 3000 | No |
| `--origin` | Origin server URL to proxy | - | Yes |

## ğŸ”§ Technical Details

### Cache Strategy
- **Only GET requests** are cached (POST, PUT, DELETE are always forwarded)
- **5-minute TTL** - cached responses expire automatically using node-cache
- **In-memory storage** - uses node-cache for fast, lightweight caching
- **Unique keys** - based on HTTP method + full URL
- **Automatic cleanup** - expired entries are automatically removed

### Cache Key Format
```
GET:http://dummyjson.com/products/1
POST:http://dummyjson.com/products
```

### Performance Benefits
- **Faster Response Times** - Cached responses return in ~1ms vs 100-500ms
- **Reduced Server Load** - Origin server handles fewer duplicate requests
- **Bandwidth Savings** - Less network traffic between proxy and origin

## ğŸ§ª Testing

```bash
# Start the proxy
node index.js --origin http://dummyjson.com --port 3000

# Terminal 2: Test cache miss
time curl http://localhost:3000/products/1

# Terminal 2: Test cache hit (should be much faster)
time curl http://localhost:3000/products/1
```

## ğŸ›  Development

```bash
# Install dev dependencies
npm install --save-dev nodemon

# Run in development mode
npm run dev

# Or with nodemon
npx nodemon index.js --origin http://dummyjson.com
```

## ğŸ“Š Cache Statistics

The proxy logs cache hits and misses:
```
[2024-07-31T10:30:15.123Z] GET /products/1 - Cache Key: GET:http://dummyjson.com/products/1
Cache MISS - forwarding to origin
[2024-07-31T10:30:16.145Z] GET /products/1 - Cache Key: GET:http://dummyjson.com/products/1
Cache HIT!
```

## ğŸ”„ Cache Implementation

### Node-Cache (Current Implementation)
```javascript
import NodeCache from 'node-cache';

// Cache with 5-minute TTL and automatic cleanup
const cache = new NodeCache({ 
    stdTTL: 300,  // 5 minutes
    checkperiod: 60  // Check for expired keys every 60 seconds
});
```

**Benefits:**
- âœ… **Zero setup** - works out of the box
- âœ… **Lightweight** - no external dependencies
- âœ… **Auto-expiration** - built-in TTL support
- âœ… **Memory efficient** - automatic cleanup of expired entries
- âœ… **Perfect for development** and small to medium production loads

## ğŸš¨ Error Handling

- **503 Service Unavailable** - When origin server is down
- **500 Internal Server Error** - For unexpected errors
- **Graceful Degradation** - Falls back to direct forwarding if cache fails

## ğŸ”® Future Enhancements

- [ ] Redis support for distributed caching
- [ ] Configurable TTL per endpoint
- [ ] Cache size limits and LRU eviction
- [ ] HTTP header-based cache control
- [ ] Cache warming strategies
- [ ] Metrics and monitoring dashboard
- [ ] Docker container support

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

<div align="center">

**[â­ Star this repository](https://github.com/Arin004joshi/Caching-Proxy)** if you found it helpful!

</div>
